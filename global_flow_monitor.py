#!/usr/bin/env python3
"""
ê¸€ë¡œë²Œ í”Œë¡œìš° ëª¨ë‹ˆí„° v2.0
========================
ê¸€ë¡œë²Œ ìê¸ˆ íë¦„ íˆíŠ¸ë§µ ëŒ€ì‹œë³´ë“œ.

v2.0 ë³€ê²½ì‚¬í•­:
    - 5ê°œ ì¹´í…Œê³ ë¦¬ (~47 í‹°ì»¤): US Sector, Regional, Thematic, Risk/Macro, Bonds/FX
    - ê·¸ë£¹ í—¤ë” + í•˜ìœ„ í‹°ì»¤ ê³„ì¸µ êµ¬ì¡°
    - yf.download() ë°°ì¹˜ ìˆ˜ì§‘ (ìˆœì°¨ 60s â†’ ë°°ì¹˜ 10-15s)
    - íˆíŠ¸ë§µ ìŠ¤íƒ€ì¼ JSON v2 â†’ HTML ëŒ€ì‹œë³´ë“œ ì—°ë™
    - ìƒˆ ì‹œê·¸ë„: Credit Spread (HYG-LQD), US Exceptionalism (SPY vs EFA)
    - ì½˜ì†”: ê·¸ë£¹ í‰ê·  ì„œë¨¸ë¦¬ í…Œì´ë¸” (--detail ë¡œ ê°œë³„ í‹°ì»¤)

v1.4 ë³€ê²½ì‚¬í•­:
    - DI-04: --export ì‹œ JSON íŒŒì¼ ìƒì„± â†’ HTML ëŒ€ì‹œë³´ë“œ ìë™ ì—°ë™
    - IA-08: pykrx ê¸°ë°˜ ê°œì¸ ë§¤ìˆ˜ íš¨ìœ¨(Buying Efficiency) ìë™ ê³„ì‚°

ì„¤ì¹˜:
    pip install yfinance pandas tabulate requests

ì‹¤í–‰:
    python global_flow_monitor.py              # ì „ì²´ ëŒ€ì‹œë³´ë“œ (ê·¸ë£¹ ì„œë¨¸ë¦¬)
    python global_flow_monitor.py --detail     # ê°œë³„ í‹°ì»¤ ì „ì²´ ì¶œë ¥
    python global_flow_monitor.py --export     # JSON v2 + CSV ë‚´ë³´ë‚´ê¸°
"""

import yfinance as yf
import pandas as pd
from datetime import datetime, timedelta
from tabulate import tabulate
import argparse
import sys
import os
import json

# IA-08: pykrx â€” optional (ê°œì¸ ë§¤ìˆ˜ íš¨ìœ¨ ê³„ì‚°ìš©)
try:
    from pykrx import stock as krx_stock
    HAS_PYKRX = True
except ImportError:
    HAS_PYKRX = False

# ============================================================
# ì„¤ì •: 5ê°œ ì¹´í…Œê³ ë¦¬ í‹°ì»¤ êµ¬ì„± (v2.0)
# ============================================================

CATEGORIES = {
    'us_sectors': {
        'label': 'US Sectors (GICS 11)',
        'icon': 'ğŸ›ï¸',
        'groups': {
            'Tech': {
                'XLK': {'name': 'Technology'},
                'XLC': {'name': 'Communication'},
            },
            'Cyclical': {
                'XLF': {'name': 'Financials'},
                'XLY': {'name': 'Consumer Disc.'},
                'XLI': {'name': 'Industrials'},
            },
            'Defensive': {
                'XLV': {'name': 'Health Care'},
                'XLP': {'name': 'Consumer Staples'},
                'XLU': {'name': 'Utilities'},
            },
            'Commodity': {
                'XLE': {'name': 'Energy'},
                'XLB': {'name': 'Materials'},
            },
            'Rate-Sensitive': {
                'XLRE': {'name': 'Real Estate'},
            },
        },
    },
    'regional': {
        'label': 'Regional Flow',
        'icon': 'ğŸŒ',
        'groups': {
            'DM Americas': {
                'SPY': {'name': 'S&P 500'},
            },
            'DM Europe': {
                'EFA': {'name': 'EAFE (Europe/Asia)'},
                'EWG': {'name': 'MSCI Germany'},
            },
            'DM Asia': {
                'EWJ': {'name': 'MSCI Japan'},
            },
            'EM Asia': {
                'FXI': {'name': 'China Large Cap'},
                'EWY': {'name': 'MSCI Korea'},
                'EWT': {'name': 'MSCI Taiwan'},
                'INDA': {'name': 'MSCI India'},
            },
            'EM Latam': {
                'EWZ': {'name': 'MSCI Brazil'},
            },
            'EM Broad': {
                'EEM': {'name': 'iShares EM'},
                'VWO': {'name': 'Vanguard EM'},
            },
        },
    },
    'thematic': {
        'label': 'Thematic / Growth',
        'icon': 'ğŸš€',
        'groups': {
            'Semiconductor': {
                'SMH': {'name': 'VanEck Semi'},
                'SOXX': {'name': 'iShares Semi'},
            },
            'Biotech': {
                'XBI': {'name': 'Biotech SPDR'},
            },
            'Disruptive': {
                'ARKK': {'name': 'ARK Innovation'},
            },
            'China Tech': {
                'KWEB': {'name': 'China Internet'},
            },
            'Leverage': {
                'SOXL': {'name': 'Semi 3x Bull'},
                'SOXS': {'name': 'Semi 3x Bear'},
            },
        },
    },
    'risk_macro': {
        'label': 'Risk / Macro',
        'icon': 'âš¡',
        'groups': {
            'Volatility': {
                '^VIX': {'name': 'VIX'},
            },
            'Safe Haven': {
                'GLD': {'name': 'Gold'},
                'TLT': {'name': '20Y+ Treasury'},
                'SHY': {'name': '1-3Y Treasury'},
            },
            'Commodities': {
                'USO': {'name': 'WTI Oil'},
            },
            'FX': {
                'UUP': {'name': 'USD Index'},
                'FXY': {'name': 'Yen ETF'},
            },
            'Credit': {
                'HYG': {'name': 'High Yield Corp'},
                'LQD': {'name': 'Inv Grade Corp'},
            },
            'Inflation': {
                'TIP': {'name': 'TIPS Bond'},
            },
        },
    },
    'bonds_fx': {
        'label': 'Bonds & FX',
        'icon': 'ğŸ¦',
        'groups': {
            'Aggregate': {
                'AGG': {'name': 'US Agg Bond'},
            },
        },
    },
}

# í•„ìˆ˜ í‹°ì»¤ â€” ë³µí•© ì‹œê·¸ë„ íŒë‹¨ì— ë°˜ë“œì‹œ í•„ìš”
REQUIRED_TICKERS = [
    'SMH', 'SOXX',       # ë°˜ë„ì²´ ë¡œí…Œì´ì…˜
    'EWY', 'EEM',         # EM ìƒëŒ€ ì„±ê³¼
    '^VIX', 'GLD', 'USO', 'UUP', 'FXY',  # ë¦¬ìŠ¤í¬ ì‹œê·¸ë„
    'HYG', 'LQD',         # í¬ë ˆë”§ ìŠ¤í”„ë ˆë“œ
    'SPY', 'EFA',          # US Exceptionalism
]


def get_all_tickers():
    """CATEGORIESì—ì„œ ì „ì²´ ê³ ìœ  í‹°ì»¤ ëª©ë¡ ì¶”ì¶œ."""
    tickers = {}  # ticker -> {name, category, group}
    for cat_key, cat in CATEGORIES.items():
        for grp_name, grp_tickers in cat['groups'].items():
            for ticker, info in grp_tickers.items():
                if ticker not in tickers:
                    tickers[ticker] = {
                        'name': info['name'],
                        'category': cat_key,
                        'group': grp_name,
                        'memberships': [],
                    }
                tickers[ticker]['memberships'].append((cat_key, grp_name))
    return tickers


def check_required_tickers(fetched_set):
    """í•„ìˆ˜ í‹°ì»¤ ìˆ˜ì§‘ ì—¬ë¶€ í™•ì¸."""
    return [t for t in REQUIRED_TICKERS if t not in fetched_set]


def print_missing_warning(missing):
    """í•„ìˆ˜ í‹°ì»¤ ëˆ„ë½ ì‹œ ìƒë‹¨ ê²½ê³ ."""
    if not missing:
        return
    width = 70
    print("\n" + "!" * width)
    print("  â›” í•„ìˆ˜ ë°ì´í„° ëˆ„ë½ ê²½ê³  â€” ë³µí•© ì‹œê·¸ë„ ì‹ ë¢°ë„ ì €í•˜")
    print("!" * width)
    for t in missing:
        print(f"  âŒ {t} â€” ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨")
    print("  â†’ í•´ë‹¹ í‹°ì»¤ì— ì˜ì¡´í•˜ëŠ” ì‹œê·¸ë„ì´ í‰ê°€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    print("!" * width)


# ============================================================
# ë°ì´í„° ìˆ˜ì§‘ â€” ë°°ì¹˜ (v2.0)
# ============================================================

def fetch_all_data(days=35):
    """yf.download() ë°°ì¹˜ ìˆ˜ì§‘ â†’ ì¹´í…Œê³ ë¦¬ë³„ ë¶„í•  ë°˜í™˜.

    Returns:
        (category_data, errors, meta)
        category_data: {cat_key: DataFrame}  â€” ê° DFì— Ticker,Name,Group,1D%,5D%,...
        errors: list of failed tickers
        meta: {'last_date', 'first_date', 'd5_refs'}
    """
    all_tickers = get_all_tickers()
    ticker_list = list(all_tickers.keys())

    end = datetime.now()
    start = end - timedelta(days=days)

    meta = {'last_date': None, 'first_date': None, 'd5_refs': {}}
    errors = []

    # ë°°ì¹˜ ë‹¤ìš´ë¡œë“œ
    print(f"  ğŸ“¡ {len(ticker_list)}ê°œ í‹°ì»¤ ë°°ì¹˜ ìˆ˜ì§‘ ì¤‘...")
    try:
        raw = yf.download(
            ticker_list,
            start=start.strftime('%Y-%m-%d'),
            end=end.strftime('%Y-%m-%d'),
            group_by='ticker',
            progress=False,
            threads=True,
        )
    except Exception as e:
        print(f"  âš ï¸  ë°°ì¹˜ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
        return {}, ticker_list, meta

    # ê°œë³„ í‹°ì»¤ ì²˜ë¦¬
    rows = []  # (ticker, row_dict)
    for ticker in ticker_list:
        try:
            # ë‹¨ì¼ í‹°ì»¤ì¼ ë•Œì™€ ë³µìˆ˜ í‹°ì»¤ì¼ ë•Œ ì»¬ëŸ¼ êµ¬ì¡°ê°€ ë‹¤ë¦„
            if len(ticker_list) == 1:
                hist = raw
            else:
                if ticker not in raw.columns.get_level_values(0):
                    errors.append(ticker)
                    continue
                hist = raw[ticker].dropna(how='all')

            if hist is None or len(hist) < 2:
                errors.append(ticker)
                continue

            close = hist['Close'].dropna()
            if len(close) < 2:
                errors.append(ticker)
                continue

            last = close.iloc[-1]
            prev = close.iloc[-2]
            first = close.iloc[0]

            # ë‚ ì§œ ì¶”ì 
            last_date = close.index[-1]
            if meta['last_date'] is None or last_date > meta['last_date']:
                meta['last_date'] = last_date
            first_date = close.index[0]
            if meta['first_date'] is None or first_date < meta['first_date']:
                meta['first_date'] = first_date

            # 5D ì°¸ì¡°
            if len(close) >= 6:
                d5_price = close.iloc[-6]
                d5_ref_date = close.index[-6].strftime('%m-%d')
            else:
                d5_price = first
                d5_ref_date = close.index[0].strftime('%m-%d') + '*'
            meta['d5_refs'][ticker] = d5_ref_date

            # ìˆ˜ìµë¥ 
            d1_ret = round((last - prev) / prev * 100, 2)
            d5_ret = round((last - d5_price) / d5_price * 100, 2)
            d30_ret = round((last - first) / first * 100, 2)

            # Z-score
            z_5d = None
            if len(close) >= 10:
                rolling_5d = close.pct_change(5) * 100
                rolling_5d = rolling_5d.dropna()
                if len(rolling_5d) >= 5 and rolling_5d.std() > 0:
                    z_5d = round((d5_ret - rolling_5d.mean()) / rolling_5d.std(), 2)

            # ê±°ë˜ëŸ‰ ë³€í™” + í‰ê·  ì¼ì¼ ë‹¬ëŸ¬ ê±°ë˜ëŸ‰
            vol = hist.get('Volume')
            vol_change = 0
            avg_dol_vol = 0  # í‰ê·  ì¼ì¼ ë‹¬ëŸ¬ ê±°ë˜ëŸ‰ ($)
            if vol is not None and len(vol) >= 5:
                vol_recent = vol.iloc[-5:].mean()
                close_recent = close.iloc[-5:].mean()
                avg_dol_vol = round(float(vol_recent * close_recent), 0)
                vol_prior = vol.iloc[-10:-5].mean() if len(vol) >= 10 else vol_recent
                if vol_prior > 0:
                    vol_change = round((vol_recent - vol_prior) / vol_prior * 100, 0)
            elif vol is not None and len(vol) >= 2:
                avg_dol_vol = round(float(vol.iloc[-2:].mean() * close.iloc[-2:].mean()), 0)

            info = all_tickers[ticker]
            row = {
                'Ticker': ticker,
                'Name': info['name'],
                'Last': round(float(last), 2),
                '1D %': d1_ret,
                '5D %': d5_ret,
                '5D Ref': d5_ref_date,
                '5D Z': z_5d,
                '30D %': d30_ret,
                'Vol Î”%': vol_change,
                'AvgDolVol': avg_dol_vol,
            }
            rows.append((ticker, row))

        except Exception as e:
            errors.append(f"{ticker}: {str(e)[:50]}")

    # ì¹´í…Œê³ ë¦¬ë³„ ë¶„í• 
    category_data = {}
    for cat_key, cat in CATEGORIES.items():
        cat_rows = []
        for grp_name, grp_tickers in cat['groups'].items():
            for ticker in grp_tickers:
                for t, row in rows:
                    if t == ticker:
                        r = dict(row)
                        r['Group'] = grp_name
                        cat_rows.append(r)
                        break
        if cat_rows:
            category_data[cat_key] = pd.DataFrame(cat_rows)

    return category_data, errors, meta


# ============================================================
# ê·¸ë£¹ ì„œë¨¸ë¦¬ (v2.0)
# ============================================================

def compute_top_movers(category_data, n=5):
    """ì „ì²´ í‹°ì»¤ ì¤‘ 5D% ê¸°ì¤€ top/bottom N ì¶”ì¶œ.

    ì œì™¸: ^VIX (ì§€í‘œ), SOXL/SOXS (ë ˆë²„ë¦¬ì§€/ì¸ë²„ìŠ¤ â€” ì™œê³¡)

    Returns:
        {'gainers': [dict, ...], 'losers': [dict, ...]}
    """
    EXCLUDE = {'^VIX', 'SOXL', 'SOXS'}

    all_rows = []
    # cat_key â†’ (icon, label) ë§¤í•‘
    cat_meta = {k: (v['icon'], v['label']) for k, v in CATEGORIES.items()}

    for cat_key, df in category_data.items():
        icon, label = cat_meta.get(cat_key, ('', ''))
        for _, row in df.iterrows():
            ticker = row['Ticker']
            if ticker in EXCLUDE:
                continue
            d5 = row.get('5D %')
            if d5 is None or pd.isna(d5):
                continue
            all_rows.append({
                'Ticker': ticker,
                'Name': row.get('Name', ''),
                '5D %': round(float(d5), 2),
                '1D %': round(float(row.get('1D %', 0)), 2) if not pd.isna(row.get('1D %')) else None,
                '30D %': round(float(row.get('30D %', 0)), 2) if not pd.isna(row.get('30D %')) else None,
                'group': row.get('Group', ''),
                'cat_icon': icon,
            })

    if not all_rows:
        return {'gainers': [], 'losers': []}

    sorted_rows = sorted(all_rows, key=lambda r: r['5D %'], reverse=True)
    gainers = sorted_rows[:n]
    losers = sorted_rows[-n:][::-1]  # worst first (ê°€ì¥ ë‚˜ìœ ê²ƒë¶€í„°)

    return {'gainers': gainers, 'losers': losers}


def compute_group_summaries(category_data):
    """ì¹´í…Œê³ ë¦¬ë³„ ê·¸ë£¹ í‰ê·  ìˆ˜ìµë¥  + ì¶”ì • í¸ì¶œì… ê³„ì‚°.

    Returns:
        {cat_key: {group_name: {
            '1D %': avg, '5D %': avg, '30D %': avg,
            'trading_impact': ì¶”ì • 5D í¸ì¶œì… ($, ì–‘ìˆ˜=ìœ ì…/ìŒìˆ˜=ìœ ì¶œ),
            'avg_dol_vol': ê·¸ë£¹ ì¼í‰ê·  ë‹¬ëŸ¬ê±°ë˜ëŸ‰ í•©ê³„ ($)
        }}}

    est_flow = Î£(ticker_AvgDolVol) Ã— 5 Ã— (group_5D% / 100)
    â†’ ê°€ê²©Ã—ê±°ë˜ëŸ‰ ê¸°ë°˜ ì¶”ì •. ì‹¤ì œ ETF í€ë“œí”Œë¡œìš°ì™€ ë‹¤ë¦„.
    """
    summaries = {}
    for cat_key, df in category_data.items():
        cat_summary = {}
        for grp_name in df['Group'].unique():
            grp = df[df['Group'] == grp_name]
            d5_avg = round(grp['5D %'].mean(), 2)
            grp_dol_vol = grp['AvgDolVol'].sum() if 'AvgDolVol' in grp.columns else 0
            est_flow = round(grp_dol_vol * 5 * (d5_avg / 100), 0)
            cat_summary[grp_name] = {
                '1D %': round(grp['1D %'].mean(), 2),
                '5D %': d5_avg,
                '30D %': round(grp['30D %'].mean(), 2),
                'trading_impact': est_flow,
                'avg_dol_vol': round(grp_dol_vol, 0),
            }
        summaries[cat_key] = cat_summary
    return summaries


# ============================================================
# ì‹œê·¸ë„ (v2.0 â€” ê¸°ì¡´ 4ê°œ + ìƒˆë¡œìš´ 2ê°œ)
# ============================================================

def compute_rotation_score(category_data):
    """ì„¹í„° ë¡œí…Œì´ì…˜ ê°•ë„: Defensive - Tech/Semi.

    v2.0: ìƒˆ ê·¸ë£¹ëª… ê¸°ë°˜. Leverage ê·¸ë£¹ ì œì™¸.
    """
    # Semiconductor from thematic
    thematic = category_data.get('thematic')
    if thematic is None:
        return None

    semi = thematic[thematic['Group'] == 'Semiconductor']
    # Defensive from us_sectors
    sectors = category_data.get('us_sectors')
    if sectors is None:
        return None

    defensive = sectors[sectors['Group'] == 'Defensive']

    if len(semi) == 0 or len(defensive) == 0:
        return None

    semi_avg = semi['5D %'].mean()
    defensive_avg = defensive['5D %'].mean()
    score = round(defensive_avg - semi_avg, 2)

    # Leverage í¬í•¨ ë¹„êµ (ê²€ì¦ìš©)
    semi_all = thematic[thematic['Group'].isin(['Semiconductor', 'Leverage'])]
    semi_all_no_bear = semi_all[~semi_all['Ticker'].isin(['SOXS'])]
    score_meta = None
    if len(semi_all_no_bear) > len(semi):
        raw = round(defensive_avg - semi_all_no_bear['5D %'].mean(), 2)
        dev = abs(raw - score) / abs(score) * 100 if score != 0 else 0
        score_meta = {'raw_with_leverage': raw, 'deviation_pct': round(dev, 0)}

    return score, score_meta


def compute_em_relative(category_data):
    """EWY vs EEM ìƒëŒ€ ì„±ê³¼ (IA-03 ë³´ì • ìœ ì§€)."""
    EWY_WEIGHT_IN_EEM = 0.12
    regional = category_data.get('regional')
    if regional is None:
        return None

    korea = regional[regional['Ticker'] == 'EWY']
    em_broad = regional[regional['Ticker'] == 'EEM']
    taiwan = regional[regional['Ticker'] == 'EWT']

    relatives = []
    if len(korea) > 0 and len(em_broad) > 0:
        ewy_5d = korea['5D %'].values[0]
        eem_5d = em_broad['5D %'].values[0]
        ewy_30d = korea['30D %'].values[0]
        eem_30d = em_broad['30D %'].values[0]

        eem_ex_kr_5d = (eem_5d - ewy_5d * EWY_WEIGHT_IN_EEM) / (1 - EWY_WEIGHT_IN_EEM)
        eem_ex_kr_30d = (eem_30d - ewy_30d * EWY_WEIGHT_IN_EEM) / (1 - EWY_WEIGHT_IN_EEM)

        diff_5d_raw = ewy_5d - eem_5d
        diff_5d_adj = ewy_5d - eem_ex_kr_5d
        diff_30d_adj = ewy_30d - eem_ex_kr_30d

        interp = 'í•œêµ­ EM ëŒ€ë¹„ ê°•ì„¸' if diff_5d_adj > 0 else 'í•œêµ­ EM ëŒ€ë¹„ ì•½ì„¸'
        relatives.append({
            'Pair': 'EWY vs EEM(ë³´ì •)',
            '5D ìƒëŒ€%': round(diff_5d_adj, 2),
            '30D ìƒëŒ€%': round(diff_30d_adj, 2),
            'í•´ì„': f'{interp} (ë³´ì • ì „ {diff_5d_raw:+.1f}%)'
        })

    if len(korea) > 0 and len(taiwan) > 0:
        diff_5d = korea['5D %'].values[0] - taiwan['5D %'].values[0]
        diff_30d = korea['30D %'].values[0] - taiwan['30D %'].values[0]
        relatives.append({
            'Pair': 'EWY vs EWT',
            '5D ìƒëŒ€%': round(diff_5d, 2),
            '30D ìƒëŒ€%': round(diff_30d, 2),
            'í•´ì„': 'í•œêµ­ ëŒ€ë§Œ ëŒ€ë¹„ ê°•ì„¸' if diff_5d > 0 else 'í•œêµ­ ëŒ€ë§Œ ëŒ€ë¹„ ì•½ì„¸ (ë°˜ë„ì²´ ë¹„ì¤‘â†‘)'
        })

    return pd.DataFrame(relatives) if relatives else None


def _get_ticker_row(category_data, ticker):
    """ì¹´í…Œê³ ë¦¬ ë°ì´í„°ì—ì„œ íŠ¹ì • í‹°ì»¤ í–‰ ì°¾ê¸°."""
    for df in category_data.values():
        match = df[df['Ticker'] == ticker]
        if len(match) > 0:
            return match.iloc[0]
    return None


def compute_risk_dashboard(category_data):
    """ë¦¬ìŠ¤í¬ ìƒíƒœ ì¢…í•© íŒë‹¨ â€” Z-score ì ì‘í˜•."""
    risk_df = category_data.get('risk_macro')
    if risk_df is None:
        return []

    signals = []
    for _, row in risk_df.iterrows():
        ticker = row['Ticker']
        d5 = row['5D %']
        z = row.get('5D Z')
        z_tag = f" Z={z:+.1f}" if z is not None else ""

        if ticker == '^VIX':
            level = row['Last']
            if z is not None and z > 2:
                signals.append(('ğŸ”´', f"VIX {level:.0f} â€” 30ì¼ ëŒ€ë¹„ ê¸‰ë“±{z_tag}"))
            elif level > 25:
                signals.append(('ğŸ”´', f"VIX {level:.0f} â€” ê³µí¬ êµ¬ê°„{z_tag}"))
            elif z is not None and z > 1:
                signals.append(('ğŸŸ¡', f"VIX {level:.0f} â€” 30ì¼ ëŒ€ë¹„ ìƒìŠ¹{z_tag}"))
            elif level > 20:
                signals.append(('ğŸŸ¡', f"VIX {level:.0f} â€” ê²½ê³„ êµ¬ê°„{z_tag}"))
            else:
                signals.append(('ğŸŸ¢', f"VIX {level:.0f} â€” ì•ˆì •{z_tag}"))

        elif ticker == 'GLD':
            if z is not None and z > 2:
                signals.append(('ğŸ”´', f"ê¸ˆ 5D {d5:+.1f}% â€” 30ì¼ ëŒ€ë¹„ ì´ìƒ ê¸‰ë“±{z_tag}"))
            elif d5 > 2:
                signals.append(('ğŸ”´', f"ê¸ˆ 5D {d5:+.1f}% â€” ì•ˆì „ìì‚° ìˆ˜ìš” ê¸‰ì¦{z_tag}"))
            elif z is not None and z > 1:
                signals.append(('ğŸŸ¡', f"ê¸ˆ 5D {d5:+.1f}% â€” 30ì¼ ëŒ€ë¹„ ìƒìŠ¹{z_tag}"))
            elif d5 > 0.5:
                signals.append(('ğŸŸ¡', f"ê¸ˆ 5D {d5:+.1f}% â€” ì•ˆì „ìì‚° ì†Œí­ ì„ í˜¸{z_tag}"))

        elif ticker == 'USO':
            if z is not None and z > 2:
                signals.append(('ğŸ”´', f"ìœ ê°€ 5D {d5:+.1f}% â€” 30ì¼ ëŒ€ë¹„ ì´ìƒ ê¸‰ë“±{z_tag}"))
            elif d5 > 5:
                signals.append(('ğŸ”´', f"ìœ ê°€ 5D {d5:+.1f}% â€” ì§€ì •í•™/ê³µê¸‰ ë¦¬ìŠ¤í¬{z_tag}"))
            elif z is not None and z < -2:
                signals.append(('ğŸŸ¢', f"ìœ ê°€ 5D {d5:+.1f}% â€” 30ì¼ ëŒ€ë¹„ ì´ìƒ ê¸‰ë½{z_tag}"))
            elif d5 < -5:
                signals.append(('ğŸŸ¢', f"ìœ ê°€ 5D {d5:+.1f}% â€” ìˆ˜ìš” ì•½í™” ìš°ë ¤{z_tag}"))

        elif ticker == 'UUP':
            if z is not None and z > 2:
                signals.append(('ğŸ”´', f"ë‹¬ëŸ¬ 5D {d5:+.1f}% â€” 30ì¼ ëŒ€ë¹„ ì´ìƒ ê°•ì„¸{z_tag}"))
            elif d5 > 1:
                signals.append(('ğŸ”´', f"ë‹¬ëŸ¬ 5D {d5:+.1f}% â€” EM ìê¸ˆìœ ì¶œ ì••ë ¥{z_tag}"))
            elif z is not None and z < -2:
                signals.append(('ğŸŸ¢', f"ë‹¬ëŸ¬ 5D {d5:+.1f}% â€” 30ì¼ ëŒ€ë¹„ ì´ìƒ ì•½ì„¸{z_tag}"))
            elif d5 < -1:
                signals.append(('ğŸŸ¢', f"ë‹¬ëŸ¬ 5D {d5:+.1f}% â€” EM ìê¸ˆìœ ì… ìš°í˜¸ì {z_tag}"))

        elif ticker == 'FXY':
            if z is not None and z > 2:
                signals.append(('ğŸŸ¡', f"ì—”í™” 5D {d5:+.1f}% â€” 30ì¼ ëŒ€ë¹„ ì´ìƒ ê°•ì„¸{z_tag}"))
            elif d5 > 2:
                signals.append(('ğŸŸ¡', f"ì—”í™” 5D {d5:+.1f}% â€” ìºë¦¬íŠ¸ë ˆì´ë“œ ì²­ì‚° ì£¼ì˜{z_tag}"))

    return signals


def generate_composite_signals(category_data):
    """ë³µí•© ì‹œê·¸ë„ ìƒì„± â€” ê¸°ì¡´ 4ê°œ + ìƒˆ 2ê°œ."""
    signals = []

    # Helper
    def get_row(ticker):
        return _get_ticker_row(category_data, ticker)

    # 1. ë°˜ë„ì²´ ë¡œí…Œì´ì…˜ + ë‹¬ëŸ¬ ê°•ì„¸ = í•œêµ­ ë§¤ë„ ì••ë ¥
    rot_result = compute_rotation_score(category_data)
    rot_score = rot_result[0] if rot_result is not None else None
    uup = get_row('UUP')

    if rot_score is not None and rot_score > 3 and uup is not None and uup['5D %'] > 0.5:
        signals.append({
            'Level': 'ğŸ”´ HIGH',
            'Signal': 'ë°˜ë„ì²´ ë¡œí…Œì´ì…˜ + ë‹¬ëŸ¬ ê°•ì„¸ ë™ì‹œ ë°œìƒ',
            'Implication': 'ì™¸ì¸ í•œêµ­ í˜„ë¬¼ ìˆœë§¤ë„ ê°€ì† ì˜ˆìƒ. ì„ ë¬¼ ìˆ ë™ë°˜ ê°€ëŠ¥.',
            'Data': f'ë¡œí…Œì´ì…˜ ìŠ¤ì½”ì–´: {rot_score}, ë‹¬ëŸ¬ 5D: +{uup["5D %"]:.1f}%'
        })

    # 2. EM ìœ ì… + í•œêµ­ ì–¸ë”í¼í¼ = ë°˜ë„ì²´ ê¸°í”¼
    em_rel = compute_em_relative(category_data)
    if em_rel is not None and len(em_rel) > 0:
        eem_row = em_rel[em_rel['Pair'] == 'EWY vs EEM(ë³´ì •)']
        if len(eem_row) > 0 and eem_row['5D ìƒëŒ€%'].values[0] < -2:
            signals.append({
                'Level': 'ğŸŸ¡ MED',
                'Signal': 'EM ìê¸ˆ ìœ ì… ì¤‘ì´ì§€ë§Œ í•œêµ­ì€ ì†Œì™¸',
                'Implication': 'ê¸€ë¡œë²Œ EM ë¡œí…Œì´ì…˜ì—ì„œ í•œêµ­=ë°˜ë„ì²´ ì¸ì‹ìœ¼ë¡œ ë¹„ì¤‘ ì¶•ì†Œ.',
                'Data': f'EWY vs EEM(ë³´ì •) 5D: {eem_row["5D ìƒëŒ€%"].values[0]:+.1f}%'
            })

    # 3. ê¸ˆ+ìœ ê°€ ë™ì‹œ ê¸‰ë“± â€” IA-05 êµì°¨ ë¶„ë¥˜
    gld = get_row('GLD')
    uso = get_row('USO')
    if gld is not None and uso is not None:
        gld_5d = gld['5D %']
        uso_5d = uso['5D %']
        if gld_5d > 1.5 and uso_5d > 3:
            tlt = get_row('TLT')
            uup_r = get_row('UUP')
            fxi = get_row('FXI')
            tlt_5d = tlt['5D %'] if tlt is not None else 0
            uup_5d = uup_r['5D %'] if uup_r is not None else 0
            fxi_5d = fxi['5D %'] if fxi is not None else 0

            cross = f'TLT 5D: {tlt_5d:+.1f}%, USD 5D: {uup_5d:+.1f}%, FXI 5D: {fxi_5d:+.1f}%'
            if tlt_5d > 1 and uup_5d > 0:
                signals.append({
                    'Level': 'ğŸ”´ HIGH',
                    'Signal': 'ê¸ˆ + ìœ ê°€ ë™ì‹œ ìƒìŠ¹ â€” ì§€ì •í•™ ë¦¬ìŠ¤í¬ (TLT ë™ë°˜ ìƒìŠ¹ í™•ì¸)',
                    'Implication': 'ì•ˆì „ìì‚° ë™ë°˜ ìƒìŠ¹ â€” ë¦¬ìŠ¤í¬ì˜¤í”„ í™•ì¸. ì¤‘ë™/ëŒ€ë§Œ ê¸´ì¥ ì ê²€ í•„ìš”.',
                    'Data': f'ê¸ˆ 5D: +{gld_5d:.1f}%, ìœ ê°€ 5D: +{uso_5d:.1f}% | {cross}'
                })
            elif uup_5d < -0.5:
                signals.append({
                    'Level': 'ğŸŸ¡ MED',
                    'Signal': 'ê¸ˆ + ìœ ê°€ ë™ì‹œ ìƒìŠ¹ â€” ë‹¬ëŸ¬ ì•½ì„¸ ì£¼ë„ (ëª…ëª© ìƒìŠ¹)',
                    'Implication': 'ë‹¬ëŸ¬ ì•½ì„¸ê°€ ì›ìì¬ ê°€ê²©ì„ ë°€ì–´ì˜¬ë¦¼. EM ìê¸ˆìœ ì…ì—ëŠ” ìš°í˜¸ì .',
                    'Data': f'ê¸ˆ 5D: +{gld_5d:.1f}%, ìœ ê°€ 5D: +{uso_5d:.1f}% | {cross}'
                })
            elif fxi_5d > 2:
                signals.append({
                    'Level': 'ğŸŸ¡ MED',
                    'Signal': 'ê¸ˆ + ìœ ê°€ ë™ì‹œ ìƒìŠ¹ â€” ì¤‘êµ­ ê²½ê¸°ë¶€ì–‘ ê¸°ëŒ€ (FXI ë™ë°˜ ìƒìŠ¹)',
                    'Implication': 'FXI ê°•ì„¸ ë™ë°˜ â€” ì¤‘êµ­ ë¶€ì–‘ì±… ê¸°ëŒ€. í•œêµ­ ìˆ˜ì¶œì£¼ì— ê¸ì •ì  ê°€ëŠ¥ì„±.',
                    'Data': f'ê¸ˆ 5D: +{gld_5d:.1f}%, ìœ ê°€ 5D: +{uso_5d:.1f}% | {cross}'
                })
            else:
                signals.append({
                    'Level': 'ğŸŸ¡ MED',
                    'Signal': 'ê¸ˆ + ìœ ê°€ ë™ì‹œ ìƒìŠ¹ â€” ì¸í”Œë ˆì´ì…˜ ê¸°ëŒ€ ìƒìŠ¹',
                    'Implication': 'ì•ˆì „ìì‚° ë™ë°˜ ì—†ì´ ì›ìì¬ë§Œ ìƒìŠ¹. ì¸í”Œë ˆ ê¸°ëŒ€ ìš°ì„¸, ê¸ˆë¦¬ ê²½ë¡œ ì£¼ì‹œ.',
                    'Data': f'ê¸ˆ 5D: +{gld_5d:.1f}%, ìœ ê°€ 5D: +{uso_5d:.1f}% | {cross}'
                })

    # 4. VIX ê¸‰ë“± + ì—”í™” ê°•ì„¸ = ìºë¦¬íŠ¸ë ˆì´ë“œ ì²­ì‚°
    vix = get_row('^VIX')
    fxy = get_row('FXY')
    if vix is not None and fxy is not None:
        vix_val = vix['Last']
        fxy_5d = fxy['5D %']
        data_str = f'VIX: {vix_val:.0f}, ì—”í™” 5D: {fxy_5d:+.1f}%'
        if vix_val > 28 and fxy_5d > 3:
            signals.append({
                'Level': 'ğŸ”´ HIGH',
                'Signal': 'VIX ê¸‰ë“± + ì—”í™” ê¸‰ë“± â€” ìºë¦¬íŠ¸ë ˆì´ë“œ ì²­ì‚° ì§„í–‰',
                'Implication': 'ì—” ìºë¦¬ ì²­ì‚° í™•ì¸ ìˆ˜ì¤€. í•œêµ­ í¬í•¨ EM ì „ë°˜ ìê¸ˆ ì´íƒˆ.',
                'Data': data_str
            })
        elif vix_val > 22 and fxy_5d > 1.5:
            signals.append({
                'Level': 'ğŸŸ¡ MED',
                'Signal': 'VIX ìƒìŠ¹ + ì—”í™” ê°•ì„¸ â€” ìºë¦¬íŠ¸ë ˆì´ë“œ ì²­ì‚° ì£¼ì˜',
                'Implication': 'ì•„ì§ ì²­ì‚° í™•ì¸ ìˆ˜ì¤€ ì•„ë‹˜ (HIGH: VIX 28+, FXY +3%). ëª¨ë‹ˆí„°ë§.',
                'Data': data_str
            })

    # 5. [NEW] Credit Spread: HYG-LQD 5D ìŠ¤í”„ë ˆë“œ
    hyg = get_row('HYG')
    lqd = get_row('LQD')
    if hyg is not None and lqd is not None:
        spread_5d = hyg['5D %'] - lqd['5D %']
        if spread_5d < -1.5:
            signals.append({
                'Level': 'ğŸ”´ HIGH',
                'Signal': f'í¬ë ˆë”§ ìŠ¤í”„ë ˆë“œ í™•ëŒ€ â€” HYG vs LQD 5D: {spread_5d:+.1f}%',
                'Implication': 'í•˜ì´ì¼ë“œ ê¸‰ë½ / íˆ¬ìë“±ê¸‰ ìƒëŒ€ ê°•ì„¸ â†’ ì‹ ìš© ë¦¬ìŠ¤í¬ í™•ëŒ€. ìœ„í—˜ ìì‚° ì „ë°˜ ê²½ê³„.',
                'Data': f'HYG 5D: {hyg["5D %"]:+.1f}%, LQD 5D: {lqd["5D %"]:+.1f}%'
            })
        elif spread_5d < -0.8:
            signals.append({
                'Level': 'ğŸŸ¡ MED',
                'Signal': f'í¬ë ˆë”§ ìŠ¤í”„ë ˆë“œ ì†Œí­ í™•ëŒ€ â€” HYG vs LQD 5D: {spread_5d:+.1f}%',
                'Implication': 'í•˜ì´ì¼ë“œ ì•½ì„¸ ì‹œì‘. ì¶”ì„¸ ì§€ì† ì‹œ ë¦¬ìŠ¤í¬ì˜¤í”„ ì „í™˜ ê°€ëŠ¥.',
                'Data': f'HYG 5D: {hyg["5D %"]:+.1f}%, LQD 5D: {lqd["5D %"]:+.1f}%'
            })

    # 6. [NEW] US Exceptionalism: SPY vs EFA
    spy = get_row('SPY')
    efa = get_row('EFA')
    if spy is not None and efa is not None:
        us_ex_5d = spy['5D %'] - efa['5D %']
        if us_ex_5d > 3:
            signals.append({
                'Level': 'ğŸŸ¡ MED',
                'Signal': f'US Exceptionalism â€” SPY vs EFA 5D: +{us_ex_5d:.1f}%',
                'Implication': 'ë¯¸êµ­ ë…ì£¼ â†’ ë¹„ë¯¸êµ­ ìì‚°ì—ì„œ ìê¸ˆ ì´íƒˆ ì••ë ¥. EM ë¡œí…Œì´ì…˜ ë¦¬ìŠ¤í¬.',
                'Data': f'SPY 5D: {spy["5D %"]:+.1f}%, EFA 5D: {efa["5D %"]:+.1f}%'
            })

    # ì‹œê·¸ë„ ë¶€ì¬ ì‹œ ì»¤ë²„ë¦¬ì§€ ëª…ì‹œ
    if not signals:
        signals.append({
            'Level': 'ğŸŸ¢ LOW',
            'Signal': 'ì£¼ìš” ë³µí•© ê²½ê³  ì‹œê·¸ë„ ì—†ìŒ (6/6 ì¡°ê±´ ë¯¸í•´ë‹¹)',
            'Implication': 'ê°ì‹œ ì¤‘ì¸ 6ê°œ ì‹œë‚˜ë¦¬ì˜¤ í•´ë‹¹ ì—†ìŒ. '
                          'ë¯¸ê°ì‹œ ì˜ì—­: ìœ„ì•ˆí™”, í•œêµ­ ì •ì¹˜/ëŒ€ë¶, ê¸€ë¡œë²Œ ìœ ë™ì„±.',
            'Data': ''
        })

    return signals


# ============================================================
# IA-08: ê°œì¸ ë§¤ìˆ˜ íš¨ìœ¨ (Buying Efficiency) â€” ê·¸ëŒ€ë¡œ ìœ ì§€
# ============================================================

def compute_buying_efficiency(date_str=None):
    """KRX ë°ì´í„° ê¸°ë°˜ ê°œì¸ ë§¤ìˆ˜ íš¨ìœ¨ ê³„ì‚°."""
    if not HAS_PYKRX:
        return None
    try:
        if date_str is None:
            today = datetime.now()
            end_dt = today.strftime('%Y%m%d')
            start_dt = (today - timedelta(days=7)).strftime('%Y%m%d')
        else:
            end_dt = date_str.replace('-', '')
            start_dt = (datetime.strptime(end_dt, '%Y%m%d') - timedelta(days=7)).strftime('%Y%m%d')

        kospi = krx_stock.get_index_ohlcv(start_dt, end_dt, "1001")
        if kospi is None or len(kospi) < 2:
            return {'error': 'ì½”ìŠ¤í”¼ ë°ì´í„° ë¶€ì¡±', 'date': end_dt}

        last_date = kospi.index[-1]
        kospi_close = kospi['ì¢…ê°€'].iloc[-1]
        kospi_prev = kospi['ì¢…ê°€'].iloc[-2]
        kospi_change = round(kospi_close - kospi_prev, 2)

        trade_date = last_date.strftime('%Y%m%d')
        trading = krx_stock.get_market_trading_value_by_investor(
            trade_date, trade_date, "KOSPI"
        )
        if trading is None or len(trading) == 0:
            return {'error': 'íˆ¬ìì ë§¤ë§¤ ë°ì´í„° ì—†ìŒ', 'date': trade_date}

        if 'ê°œì¸' in trading.index:
            individual_net = trading.loc['ê°œì¸', 'ìˆœë§¤ìˆ˜']
            individual_net_trillion = round(individual_net / 1_000_000_000_000, 2)
        else:
            return {'error': 'ê°œì¸ íˆ¬ìì ë°ì´í„° ì—†ìŒ', 'date': trade_date}

        if abs(individual_net_trillion) < 0.01:
            efficiency = None
        else:
            efficiency = round(kospi_change / individual_net_trillion, 1)

        foreign_net_trillion = None
        if 'ì™¸êµ­ì¸' in trading.index:
            foreign_net = trading.loc['ì™¸êµ­ì¸', 'ìˆœë§¤ìˆ˜']
            foreign_net_trillion = round(foreign_net / 1_000_000_000_000, 2)

        return {
            'date': last_date.strftime('%Y-%m-%d'),
            'kospi_close': kospi_close,
            'kospi_change': kospi_change,
            'individual_net_buy': individual_net_trillion,
            'foreign_net_buy': foreign_net_trillion,
            'efficiency': efficiency,
            'error': None,
        }
    except Exception as e:
        return {'error': f'KRX ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨: {str(e)[:80]}'}


# ============================================================
# JSON v2 ì¶œë ¥
# ============================================================

def export_json_v2(category_data, summaries, composite, meta, buying_eff=None):
    """ê³„ì¸µì  JSON v2 ì¶œë ¥.

    {version: 2, categories: {cat_key: {label, icon, groups, summary}}, signals, kpi, ...}
    """

    def nan_to_none(val):
        if pd.isna(val):
            return None
        return val

    def row_to_dict(row):
        return {k: nan_to_none(v) for k, v in row.items()}

    data = {
        'version': 2,
        'generated_at': datetime.now().strftime('%Y-%m-%d %H:%M KST'),
        'data_date': None,
        'categories': {},
        'signals': [],
        'kpi': {},
        'buying_efficiency': None,
    }

    # ë°ì´í„° ê¸°ì¤€ì¼
    if meta.get('last_date') is not None:
        ld = meta['last_date']
        weekdays_ko = ['ì›”', 'í™”', 'ìˆ˜', 'ëª©', 'ê¸ˆ', 'í† ', 'ì¼']
        data['data_date'] = ld.strftime('%Y-%m-%d') + f' ({weekdays_ko[ld.weekday()]})'

    # ì¹´í…Œê³ ë¦¬ë³„ êµ¬ì¡°í™”
    for cat_key, cat_config in CATEGORIES.items():
        df = category_data.get(cat_key)
        if df is None:
            continue

        cat_out = {
            'label': cat_config['label'],
            'icon': cat_config['icon'],
            'groups': {},
            'summary': summaries.get(cat_key, {}),
        }

        for grp_name in cat_config['groups']:
            grp_rows = df[df['Group'] == grp_name]
            if len(grp_rows) > 0:
                cat_out['groups'][grp_name] = [row_to_dict(r) for _, r in grp_rows.iterrows()]

        data['categories'][cat_key] = cat_out

    # ë³µí•© ì‹œê·¸ë„
    if composite:
        for s in composite:
            data['signals'].append({
                'level': s.get('Level', ''),
                'signal': s.get('Signal', ''),
                'implication': s.get('Implication', ''),
                'data': s.get('Data', ''),
            })

    # KPI
    rot_result = compute_rotation_score(category_data)
    if rot_result is not None:
        data['kpi']['rotation_score'] = rot_result[0]

    em_rel = compute_em_relative(category_data)
    if em_rel is not None and len(em_rel) > 0:
        eem_row = em_rel[em_rel['Pair'] == 'EWY vs EEM(ë³´ì •)']
        if len(eem_row) > 0:
            data['kpi']['em_relative_5d'] = eem_row['5D ìƒëŒ€%'].values[0]

    vix = _get_ticker_row(category_data, '^VIX')
    if vix is not None:
        data['kpi']['vix'] = float(vix['Last'])

    hyg = _get_ticker_row(category_data, 'HYG')
    lqd = _get_ticker_row(category_data, 'LQD')
    if hyg is not None and lqd is not None:
        data['kpi']['hyg_lqd_spread_5d'] = round(hyg['5D %'] - lqd['5D %'], 2)

    spy = _get_ticker_row(category_data, 'SPY')
    efa = _get_ticker_row(category_data, 'EFA')
    if spy is not None and efa is not None:
        data['kpi']['spy_vs_efa_5d'] = round(spy['5D %'] - efa['5D %'], 2)

    # v1 í˜¸í™˜ ë ˆì´ì–´
    v1 = {'rotation': [], 'em': [], 'risk': []}
    v1_map = {
        'us_sectors': 'rotation',
        'thematic': 'rotation',
        'regional': 'em',
        'risk_macro': 'risk',
        'bonds_fx': 'risk',
    }
    for cat_key, df in category_data.items():
        target = v1_map.get(cat_key, 'risk')
        cols = ['Group', 'Ticker', 'Name', '1D %', '5D %', '5D Ref', '30D %', 'Vol Î”%']
        available = [c for c in cols if c in df.columns]
        records = df[available].to_dict('records')
        for r in records:
            for k, v in r.items():
                if pd.isna(v):
                    r[k] = None
        v1[target].extend(records)
    data['_v1_compat'] = v1

    # Top Movers
    data['top_movers'] = compute_top_movers(category_data, n=5)

    # ë§¤ìˆ˜ íš¨ìœ¨
    if buying_eff is not None and buying_eff.get('error') is None:
        data['buying_efficiency'] = buying_eff

    # ì €ì¥
    filepath = 'flow_monitor_latest.json'
    with open(filepath, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)
    print(f"  ğŸ’¾ JSON v2: {filepath}")

    return filepath


# ============================================================
# ì½˜ì†” ì¶œë ¥
# ============================================================

def print_header(title, data_date=None):
    width = 70
    print("\n" + "â•" * width)
    print(f"  {title}")
    run_time = datetime.now().strftime('%Y-%m-%d %H:%M KST')
    if data_date is not None:
        weekdays_ko = ['ì›”', 'í™”', 'ìˆ˜', 'ëª©', 'ê¸ˆ', 'í† ', 'ì¼']
        wd = weekdays_ko[data_date.weekday()]
        print(f"  ì‹¤í–‰: {run_time}  |  ë°ì´í„° ê¸°ì¤€: {data_date.strftime('%Y-%m-%d')} ({wd})")
    else:
        print(f"  {run_time}")
    print("â•" * width)


def print_group_summary(summaries):
    """ê·¸ë£¹ í‰ê·  ì„œë¨¸ë¦¬ í…Œì´ë¸” ì¶œë ¥."""
    rows = []
    for cat_key, cat_config in CATEGORIES.items():
        grp_data = summaries.get(cat_key, {})
        for grp_name, vals in grp_data.items():
            rows.append({
                'Category': cat_config['label'][:16],
                'Group': grp_name,
                '1D %': vals['1D %'],
                '5D %': vals['5D %'],
                '30D %': vals['30D %'],
            })

    if rows:
        df = pd.DataFrame(rows)
        print(tabulate(df, headers='keys', tablefmt='simple', showindex=False,
                       numalign='right', floatfmt='+.2f'))


def print_detail_tables(category_data):
    """ê°œë³„ í‹°ì»¤ ì „ì²´ ì¶œë ¥ (--detail)."""
    for cat_key, cat_config in CATEGORIES.items():
        df = category_data.get(cat_key)
        if df is None:
            continue
        print(f"\nâ”€â”€ {cat_config['icon']} {cat_config['label']} {'â”€' * 40}")
        cols = ['Group', 'Ticker', 'Name', 'Last', '1D %', '5D %', '5D Z', '30D %', 'Vol Î”%']
        available = [c for c in cols if c in df.columns]
        print(tabulate(df[available], headers='keys', tablefmt='simple',
                       showindex=False, numalign='right', floatfmt='.2f'))


def print_signals(title, signals):
    print(f"\nâ”€â”€ {title} {'â”€' * max(1, 50 - len(title))}")
    for s in signals:
        if isinstance(s, tuple):
            print(f"  {s[0]} {s[1]}")
        elif isinstance(s, dict):
            print(f"  {s['Level']}  {s['Signal']}")
            print(f"         â†’ {s['Implication']}")
            if s.get('Data'):
                print(f"         ğŸ“Š {s['Data']}")
            print()


# ============================================================
# ë©”ì¸ ëŒ€ì‹œë³´ë“œ (v2.0)
# ============================================================

def run_dashboard(detail=False, export=False):
    """ë©”ì¸ ëŒ€ì‹œë³´ë“œ ì‹¤í–‰."""

    # ë°°ì¹˜ ìˆ˜ì§‘
    category_data, errors, meta = fetch_all_data(days=35)

    if not category_data:
        print("  âš ï¸  ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨. ë„¤íŠ¸ì›Œí¬ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        return

    # í•„ìˆ˜ í‹°ì»¤ í™•ì¸
    fetched_set = set()
    for df in category_data.values():
        fetched_set.update(df['Ticker'].values)
    missing = check_required_tickers(fetched_set)
    print_missing_warning(missing)

    # ê·¸ë£¹ ì„œë¨¸ë¦¬ ê³„ì‚°
    summaries = compute_group_summaries(category_data)

    # í—¤ë”
    print_header("ê¸€ë¡œë²Œ í”Œë¡œìš° ëª¨ë‹ˆí„° v2.0 â€” íˆíŠ¸ë§µ ëŒ€ì‹œë³´ë“œ", meta.get('last_date'))

    # ì„œë¨¸ë¦¬ ë˜ëŠ” ë””í…Œì¼
    if detail:
        print_detail_tables(category_data)
    else:
        print(f"\nâ”€â”€ ğŸ“Š ê·¸ë£¹ í‰ê·  ì„œë¨¸ë¦¬ {'â”€' * 40}")
        print_group_summary(summaries)
        print(f"\n  â„¹ï¸  ê°œë³„ í‹°ì»¤ í™•ì¸: --detail í”Œë˜ê·¸ ì‚¬ìš©")

    # ë¡œí…Œì´ì…˜ ìŠ¤ì½”ì–´
    rot_result = compute_rotation_score(category_data)
    if rot_result is not None:
        rot_score, score_meta = rot_result
        direction = "â†’ Growthâ†’Value ì§„í–‰" if rot_score > 0 else "â†’ Valueâ†’Growth ë³µê·€"
        bar = "â–ˆ" * min(abs(int(rot_score)), 20)
        print(f"\n  ğŸ“Š ë¡œí…Œì´ì…˜ ìŠ¤ì½”ì–´ (5D): {rot_score:+.1f}  {direction}")
        print(f"     [{bar}]")
        if score_meta is not None:
            raw = score_meta['raw_with_leverage']
            dev = score_meta['deviation_pct']
            print(f"     ê²€ì¦: ë ˆë²„ë¦¬ì§€ í¬í•¨ ì‹œ {raw:+.1f} (í¸ì°¨ {dev:.0f}%)")

    # EM ìƒëŒ€ ì„±ê³¼
    em_rel = compute_em_relative(category_data)
    if em_rel is not None:
        print(f"\nâ”€â”€ í•œêµ­ ìƒëŒ€ ì„±ê³¼ {'â”€' * 40}")
        print(tabulate(em_rel, headers='keys', tablefmt='simple', showindex=False))

    # ë¦¬ìŠ¤í¬ ì‹œê·¸ë„
    risk_signals = compute_risk_dashboard(category_data)
    if risk_signals:
        print_signals("ë¦¬ìŠ¤í¬ ìƒíƒœ íŒë‹¨", risk_signals)

    # ë³µí•© ì‹œê·¸ë„
    composite = generate_composite_signals(category_data)
    print_signals("ë³µí•© ì‹œê·¸ë„ â€” ì™¸ì¸ í–‰ë™ ì˜ˆì¸¡", composite)

    # ë§¤ìˆ˜ íš¨ìœ¨
    buying_eff = None
    buying_eff = compute_buying_efficiency()
    if buying_eff is not None:
        print(f"\nâ”€â”€ ê°œì¸ ë§¤ìˆ˜ íš¨ìœ¨ (Buying Efficiency) {'â”€' * 22}")
        if buying_eff.get('error'):
            print(f"  âš ï¸  {buying_eff['error']}")
        else:
            kospi_chg = buying_eff['kospi_change']
            ind_net = buying_eff['individual_net_buy']
            eff = buying_eff['efficiency']
            fgn_net = buying_eff.get('foreign_net_buy')

            chg_color = "â–²" if kospi_chg > 0 else "â–¼" if kospi_chg < 0 else "â”€"
            print(f"  ğŸ“… ê¸°ì¤€ì¼: {buying_eff['date']}")
            print(f"  ğŸ“Š ì½”ìŠ¤í”¼: {buying_eff['kospi_close']:,.0f} ({chg_color}{kospi_chg:+.1f}p)")
            print(f"  ğŸ§‘ ê°œì¸ ìˆœë§¤ìˆ˜: {ind_net:+.2f}ì¡°ì›")
            if fgn_net is not None:
                print(f"  ğŸŒ ì™¸ì¸ ìˆœë§¤ìˆ˜: {fgn_net:+.2f}ì¡°ì›")
            if eff is not None:
                if eff > 0:
                    label = "ê°œì¸ ë§¤ìˆ˜ â†’ ì§€ìˆ˜ ìƒìŠ¹ (íš¨ìœ¨ì )"
                elif eff > -5:
                    label = "ê°œì¸ ë§¤ìˆ˜ â†’ ì™¸ì¸ ë§¤ë„ ìƒì‡„ ì¤‘"
                else:
                    label = "ê°œì¸ ë§¤ìˆ˜ì—ë„ ì§€ìˆ˜ í•˜ë½ â€” ë°©ì–´ ì‹¤íŒ¨"
                print(f"  ğŸ’¡ ë§¤ìˆ˜ íš¨ìœ¨: {eff:+.1f} ({label})")
            else:
                print(f"  ğŸ’¡ ë§¤ìˆ˜ íš¨ìœ¨: ê³„ì‚° ë¶ˆê°€ (ìˆœë§¤ìˆ˜ â‰ˆ 0)")
    elif not HAS_PYKRX:
        print(f"\nâ”€â”€ ê°œì¸ ë§¤ìˆ˜ íš¨ìœ¨ {'â”€' * 33}")
        print(f"  â„¹ï¸  pykrx ë¯¸ì„¤ì¹˜. 'pip install pykrx'ë¡œ ì„¤ì¹˜ ì‹œ ìë™ í™œì„±í™”.")

    # ì—ëŸ¬
    if errors:
        print(f"\n  âš ï¸  ìˆ˜ì§‘ ì‹¤íŒ¨ ({len(errors)}ê°œ): {', '.join(str(e) for e in errors[:10])}")

    # ë‚´ë³´ë‚´ê¸°
    if export:
        timestamp = datetime.now().strftime('%Y%m%d_%H%M')
        for cat_key, df in category_data.items():
            filename = f"flow_monitor_{cat_key}_{timestamp}.csv"
            df.to_csv(filename, index=False, encoding='utf-8-sig')
            print(f"  ğŸ’¾ CSV: {filename}")
        export_json_v2(category_data, summaries, composite, meta, buying_eff)

    # í‘¸í„°
    if meta.get('last_date'):
        ld = meta['last_date']
        weekdays_ko = ['ì›”', 'í™”', 'ìˆ˜', 'ëª©', 'ê¸ˆ', 'í† ', 'ì¼']
        wd = weekdays_ko[ld.weekday()]
        date_note = f"  ë°ì´í„° ê¸°ì¤€: {ld.strftime('%Y-%m-%d')} ({wd})"
    else:
        date_note = "  ë°ì´í„° ê¸°ì¤€: ìˆ˜ì§‘ ì‹¤íŒ¨"

    print("\n" + "â•" * 70)
    print(date_note)
    print(f"  ì´ {len(fetched_set)}ê°œ í‹°ì»¤ ìˆ˜ì§‘ ì™„ë£Œ")
    print("  ë°ì´í„° ì†ŒìŠ¤: Yahoo Finance (15ë¶„ ì§€ì—°)" +
          (" + KRX (pykrx)" if HAS_PYKRX else ""))
    print("â•" * 70 + "\n")


# ============================================================
# ì§„ì…ì 
# ============================================================

if __name__ == '__main__':
    parser = argparse.ArgumentParser(description='ê¸€ë¡œë²Œ í”Œë¡œìš° ëª¨ë‹ˆí„° v2.0')
    parser.add_argument('--detail', action='store_true', help='ê°œë³„ í‹°ì»¤ ì „ì²´ ì¶œë ¥')
    parser.add_argument('--export', action='store_true', help='JSON v2 + CSV ë‚´ë³´ë‚´ê¸°')

    args = parser.parse_args()
    run_dashboard(detail=args.detail, export=args.export)
